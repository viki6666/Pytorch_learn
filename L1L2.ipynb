{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L1L2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viki6666/Pytorch_learn/blob/master/L1L2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H39yAUqQLd9",
        "colab_type": "code",
        "outputId": "d9cccef0-f974-4e83-92b8-7e105d251e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')  # 将google硬盘挂载在/comtent/drive/目录上面"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOOailGcQfFj",
        "colab_type": "code",
        "outputId": "6f1d5e89-4976-4dee-bf0f-735919f5844c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "# 1. 加载MNIST手写数字数据集数据和标签\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, ), (0.5, ))])\n",
        "trainset = datasets.MNIST(root='./data', train=True,\n",
        "                            download=True, transform=transform)\n",
        "trainsetloader = torch.utils.data.DataLoader(trainset, batch_size=20000, shuffle=True)\n",
        "\n",
        "testset = datasets.MNIST(root='./data', train=True,\n",
        "                            download=True, transform=transform)\n",
        "testsetloader = torch.utils.data.DataLoader(testset, batch_size=20000, shuffle=True)\n",
        "\n",
        "#######如果你不放心数据有没有加载出可以将图片显示出来看下#######\n",
        "# dataiter = iter(trainsetloader)\n",
        "# images, labels = dataiter.next()\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.imshow(images[0].numpy().squeeze())\n",
        "# plt.show()\n",
        "# print(images.shape)\n",
        "# print(labels.shape)\n",
        "##########上面这段是显示图片的代码#############\n",
        "\n",
        "\n",
        "# 2. 设计网络结构\n",
        "first_in, first_out, second_out = 28*28,  128, 10\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(first_in, first_out),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(first_out, second_out),\n",
        ")\n",
        "\n",
        "# 3. 设计损失函数\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# 4. 设置用于自动调节神经网络参数的优化器\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 5. 训练神经网络（重复训练10次）\n",
        "for t in range(10):\n",
        "    for i, one_batch in enumerate(trainsetloader,0):\n",
        "        data,label = one_batch\n",
        "        data[0].view(1,784)# 将28x28的图片变成784的向量\n",
        "        data = data.view(data.shape[0],-1)\n",
        "\n",
        "        # 让神经网络根据现有的参数，根据当前的输入计算一个输出\n",
        "        model_output = model(data)\n",
        "        # 5.1 用所设计算损失(误差)函数计算误差\n",
        "        loss = loss_fn(model_output , label)\n",
        "        if i%500 == 0:\n",
        "            print(loss)\n",
        "        # 5.2 每次训练前清零之前计算的梯度(导数)\n",
        "        optimizer.zero_grad()\n",
        "        # 5.3 根据误差反向传播计算误差对各个权重的导数\n",
        "        loss.backward()\n",
        "        # 5.4 根据优化器里面的算法自动调整神经网络权重\n",
        "        optimizer.step()\n",
        "\n",
        "# 保存下训练好的模型,省得下次再重新训练\n",
        "torch.save(model,'./my_handwrite_recognize_model.pt')\n",
        "\n",
        "\n",
        "##########现在你已经训练好了#################\n",
        "# 6. 用这个神经网络解决你的问题，比如手写数字识别，输入一个图片矩阵，然后模型返回一个数字\n",
        "testdataiter = iter(testsetloader)\n",
        "testimages, testlabels = testdataiter.next()\n",
        "\n",
        "img_vector = testimages[0].squeeze().view(1,-1)\n",
        "# 模型返回的是一个1x10的矩阵，第几个元素值最大那就是表示模型认为当前图片是数字几\n",
        "result_digit = model(img_vector)\n",
        "print(\"该手写数字图片识别结果为：\", result_digit.max(1)[1],\"标签为：\",testlabels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:04, 2372798.88it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 141388.35it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2319882.04it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 50683.01it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "tensor(2.3007, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2332, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1814, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1335, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0871, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0470, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0031, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9608, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9173, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8724, grad_fn=<NllLossBackward>)\n",
            "该手写数字图片识别结果为： tensor([0]) 标签为： tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7GGyqRbED0b",
        "colab_type": "text"
      },
      "source": [
        "L1正则化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8_fbZz6qM74",
        "colab_type": "code",
        "outputId": "4f3da6fa-cbf3-4d79-e726-8bb2a49f2e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "# 1. 加载MNIST手写数字数据集数据和标签\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, ), (0.5, ))])\n",
        "trainset = datasets.MNIST(root='./data', train=True,\n",
        "                            download=True, transform=transform)\n",
        "trainsetloader = torch.utils.data.DataLoader(trainset, batch_size=20000, shuffle=True)\n",
        "\n",
        "testset = datasets.MNIST(root='./data', train=True,\n",
        "                            download=True, transform=transform)\n",
        "testsetloader = torch.utils.data.DataLoader(testset, batch_size=20000, shuffle=True)\n",
        "\n",
        "#######如果你不放心数据有没有加载出可以将图片显示出来看下#######\n",
        "# dataiter = iter(trainsetloader)\n",
        "# images, labels = dataiter.next()\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.imshow(images[0].numpy().squeeze())\n",
        "# plt.show()\n",
        "# print(images.shape)\n",
        "# print(labels.shape)\n",
        "##########上面这段是显示图片的代码#############\n",
        "\n",
        "\n",
        "# 2. 设计网络结构\n",
        "first_in, first_out, second_out = 28*28,  128, 10\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(first_in, first_out),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(first_out, second_out),\n",
        ")\n",
        "\n",
        "# 3. 设计损失函数\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# 4. 设置用于自动调节神经网络参数的优化器\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 5. 训练神经网络（重复训练10次）\n",
        "for t in range(30):\n",
        "    for i, one_batch in enumerate(trainsetloader,0):\n",
        "        data,label = one_batch\n",
        "        data[0].view(1,784)# 将28x28的图片变成784的向量\n",
        "        data = data.view(data.shape[0],-1)\n",
        "\n",
        "        # 让神经网络根据现有的参数，根据当前的输入计算一个输出\n",
        "        model_output = model(data)\n",
        "        # 5.1 用所设计算损失(误差)函数计算误差\n",
        "        #L1\n",
        "        regularization_loss = 0\n",
        "        for param in model.parameters():\n",
        "            regularization_loss += torch.sum(torch.abs(param))\n",
        "        classify_loss = loss_fn(model_output, label)\n",
        "        loss = classify_loss + 0.001*regularization_loss\n",
        "       # loss = loss_fn(model_output , label)\n",
        "        if i%500 == 0:\n",
        "            print(loss)\n",
        "        # 5.2 每次训练前清零之前计算的梯度(导数)\n",
        "        optimizer.zero_grad()\n",
        "        # 5.3 根据误差反向传播计算误差对各个权重的导数\n",
        "        loss.backward()\n",
        "        # 5.4 根据优化器里面的算法自动调整神经网络权重\n",
        "        optimizer.step()\n",
        "\n",
        "# 保存下训练好的模型,省得下次再重新训练\n",
        "torch.save(model,'./my_handwrite_recognize_model.pt')\n",
        "\n",
        "\n",
        "##########现在你已经训练好了#################\n",
        "# 6. 用这个神经网络解决你的问题，比如手写数字识别，输入一个图片矩阵，然后模型返回一个数字\n",
        "testdataiter = iter(testsetloader)\n",
        "testimages, testlabels = testdataiter.next()\n",
        "\n",
        "img_vector = testimages[0].squeeze().view(1,-1)\n",
        "# 模型返回的是一个1x10的矩阵，第几个元素值最大那就是表示模型认为当前图片是数字几\n",
        "result_digit = model(img_vector)\n",
        "print(\"该手写数字图片识别结果为：\", result_digit.max(1)[1],\"标签为：\",testlabels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8684109.86it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 135969.13it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2207649.61it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 51630.81it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "tensor(4.1749, grad_fn=<AddBackward0>)\n",
            "tensor(4.1038, grad_fn=<AddBackward0>)\n",
            "tensor(4.0433, grad_fn=<AddBackward0>)\n",
            "tensor(3.9846, grad_fn=<AddBackward0>)\n",
            "tensor(3.9309, grad_fn=<AddBackward0>)\n",
            "tensor(3.8785, grad_fn=<AddBackward0>)\n",
            "tensor(3.8245, grad_fn=<AddBackward0>)\n",
            "tensor(3.7753, grad_fn=<AddBackward0>)\n",
            "tensor(3.7229, grad_fn=<AddBackward0>)\n",
            "tensor(3.6712, grad_fn=<AddBackward0>)\n",
            "tensor(3.6139, grad_fn=<AddBackward0>)\n",
            "tensor(3.5684, grad_fn=<AddBackward0>)\n",
            "tensor(3.5189, grad_fn=<AddBackward0>)\n",
            "tensor(3.4637, grad_fn=<AddBackward0>)\n",
            "tensor(3.4135, grad_fn=<AddBackward0>)\n",
            "tensor(3.3658, grad_fn=<AddBackward0>)\n",
            "tensor(3.3120, grad_fn=<AddBackward0>)\n",
            "tensor(3.2672, grad_fn=<AddBackward0>)\n",
            "tensor(3.2225, grad_fn=<AddBackward0>)\n",
            "tensor(3.1708, grad_fn=<AddBackward0>)\n",
            "tensor(3.1184, grad_fn=<AddBackward0>)\n",
            "tensor(3.0737, grad_fn=<AddBackward0>)\n",
            "tensor(3.0258, grad_fn=<AddBackward0>)\n",
            "tensor(2.9793, grad_fn=<AddBackward0>)\n",
            "tensor(2.9343, grad_fn=<AddBackward0>)\n",
            "tensor(2.8953, grad_fn=<AddBackward0>)\n",
            "tensor(2.8460, grad_fn=<AddBackward0>)\n",
            "tensor(2.8015, grad_fn=<AddBackward0>)\n",
            "tensor(2.7573, grad_fn=<AddBackward0>)\n",
            "tensor(2.7214, grad_fn=<AddBackward0>)\n",
            "该手写数字图片识别结果为： tensor([6]) 标签为： tensor(6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j-kVaodELFS",
        "colab_type": "text"
      },
      "source": [
        "L2正则化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umr9BfWdDqpJ",
        "colab_type": "code",
        "outputId": "2e042429-9224-4bfe-a381-7d063e5e9285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "# 1. 加载MNIST手写数字数据集数据和标签\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, ), (0.5, ))])\n",
        "trainset = datasets.MNIST(root='./data', train=True,\n",
        "                            download=True, transform=transform)\n",
        "trainsetloader = torch.utils.data.DataLoader(trainset, batch_size=20000, shuffle=True)\n",
        "\n",
        "testset = datasets.MNIST(root='./data', train=True,\n",
        "                            download=True, transform=transform)\n",
        "testsetloader = torch.utils.data.DataLoader(testset, batch_size=20000, shuffle=True)\n",
        "\n",
        "#######如果你不放心数据有没有加载出可以将图片显示出来看下#######\n",
        "# dataiter = iter(trainsetloader)\n",
        "# images, labels = dataiter.next()\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.imshow(images[0].numpy().squeeze())\n",
        "# plt.show()\n",
        "# print(images.shape)\n",
        "# print(labels.shape)\n",
        "##########上面这段是显示图片的代码#############\n",
        "\n",
        "\n",
        "# 2. 设计网络结构\n",
        "first_in, first_out, second_out = 28*28,  128, 10\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(first_in, first_out),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(first_out, second_out),\n",
        ")\n",
        "\n",
        "# 3. 设计损失函数\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# 4. 设置用于自动调节神经网络参数的优化器\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 5. 训练神经网络（重复训练10次）\n",
        "for t in range(30):\n",
        "    for i, one_batch in enumerate(trainsetloader,0):\n",
        "        data,label = one_batch\n",
        "        data[0].view(1,784)# 将28x28的图片变成784的向量\n",
        "        data = data.view(data.shape[0],-1)\n",
        "\n",
        "        # 让神经网络根据现有的参数，根据当前的输入计算一个输出\n",
        "        model_output = model(data)\n",
        "        # 5.1 用所设计算损失(误差)函数计算误差\n",
        "        #L2\n",
        "        regularization_loss = 0\n",
        "        for param in model.parameters():\n",
        "            regularization_loss += torch.sum((param**2))\n",
        "        classify_loss = loss_fn(model_output, label)\n",
        "        loss = classify_loss + 0.001*regularization_loss\n",
        "       # loss = loss_fn(model_output , label)\n",
        "        if i%500 == 0:\n",
        "            print(loss)\n",
        "        # 5.2 每次训练前清零之前计算的梯度(导数)\n",
        "        optimizer.zero_grad()\n",
        "        # 5.3 根据误差反向传播计算误差对各个权重的导数\n",
        "        loss.backward()\n",
        "        # 5.4 根据优化器里面的算法自动调整神经网络权重\n",
        "        optimizer.step()\n",
        "\n",
        "# 保存下训练好的模型,省得下次再重新训练\n",
        "torch.save(model,'./my_handwrite_recognize_model.pt')\n",
        "\n",
        "\n",
        "##########现在你已经训练好了#################\n",
        "# 6. 用这个神经网络解决你的问题，比如手写数字识别，输入一个图片矩阵，然后模型返回一个数字\n",
        "testdataiter = iter(testsetloader)\n",
        "testimages, testlabels = testdataiter.next()\n",
        "\n",
        "img_vector = testimages[0].squeeze().view(1,-1)\n",
        "# 模型返回的是一个1x10的矩阵，第几个元素值最大那就是表示模型认为当前图片是数字几\n",
        "result_digit = model(img_vector)\n",
        "print(\"该手写数字图片识别结果为：\", result_digit.max(1)[1],\"标签为：\",testlabels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3582, grad_fn=<AddBackward0>)\n",
            "tensor(2.2836, grad_fn=<AddBackward0>)\n",
            "tensor(2.2245, grad_fn=<AddBackward0>)\n",
            "tensor(2.1746, grad_fn=<AddBackward0>)\n",
            "tensor(2.1276, grad_fn=<AddBackward0>)\n",
            "tensor(2.0819, grad_fn=<AddBackward0>)\n",
            "tensor(2.0393, grad_fn=<AddBackward0>)\n",
            "tensor(1.9939, grad_fn=<AddBackward0>)\n",
            "tensor(1.9480, grad_fn=<AddBackward0>)\n",
            "tensor(1.9095, grad_fn=<AddBackward0>)\n",
            "tensor(1.8653, grad_fn=<AddBackward0>)\n",
            "tensor(1.8243, grad_fn=<AddBackward0>)\n",
            "tensor(1.7816, grad_fn=<AddBackward0>)\n",
            "tensor(1.7409, grad_fn=<AddBackward0>)\n",
            "tensor(1.6974, grad_fn=<AddBackward0>)\n",
            "tensor(1.6632, grad_fn=<AddBackward0>)\n",
            "tensor(1.6230, grad_fn=<AddBackward0>)\n",
            "tensor(1.5848, grad_fn=<AddBackward0>)\n",
            "tensor(1.5537, grad_fn=<AddBackward0>)\n",
            "tensor(1.5174, grad_fn=<AddBackward0>)\n",
            "tensor(1.4802, grad_fn=<AddBackward0>)\n",
            "tensor(1.4493, grad_fn=<AddBackward0>)\n",
            "tensor(1.4158, grad_fn=<AddBackward0>)\n",
            "tensor(1.3852, grad_fn=<AddBackward0>)\n",
            "tensor(1.3527, grad_fn=<AddBackward0>)\n",
            "tensor(1.3262, grad_fn=<AddBackward0>)\n",
            "tensor(1.2910, grad_fn=<AddBackward0>)\n",
            "tensor(1.2651, grad_fn=<AddBackward0>)\n",
            "tensor(1.2408, grad_fn=<AddBackward0>)\n",
            "tensor(1.2147, grad_fn=<AddBackward0>)\n",
            "该手写数字图片识别结果为： tensor([3]) 标签为： tensor(3)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}